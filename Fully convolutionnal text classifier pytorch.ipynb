{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and gpu init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "num_device = 0\n",
    "device = torch.device(\"cuda:\" + str(num_device) if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(num_device)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv('lol',\"22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_DIR = os.getenv('VH_INPUTS_DIR','/valohai/inputs/')\n",
    "dataset = os.path.join(INPUTS_DIR, 'dataset')\n",
    "word_vectors = os.path.join(INPUTS_DIR, 'word_vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessings and iterators on train/test dataset for batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "def clean_line(line):\n",
    "    hashtag = re.compile('#[^ \\t\\n\\r\\f\\v]+')\n",
    "    username = re.compile('@[^ \\t\\n\\r\\f\\v]+')\n",
    "    url = re.compile('https?[^ \\t\\n\\r\\f\\v]*')\n",
    "    junk = re.compile('[\"¤#%&()*+-/;<=>@[\\]^_`{|}~\\\\;\\(\\)\\'\\\"\\*\\`\\´\\‘\\’…\\\\\\/\\{\\}\\|\\+><~\\[\\]\\“\\”%=\\$§]')\n",
    "    ponctu = re.compile('[.!?,:]')\n",
    "    number = re.compile('(^[0-9]+)|([0-9]+)')\n",
    "    rep = re.compile(r'(.)\\1{2,}')\n",
    "    emo = re.compile('[\\u233a-\\U0001f9ff]')\n",
    "\n",
    "    if line.startswith('\"') :\n",
    "        line = line[1:]\n",
    "    if line.endswith('\"') :\n",
    "        line = line[:-1]\n",
    "        \n",
    "    line = re.sub(url,' url ', line) # replace every url with ' url '\n",
    "    \n",
    "    def subfct1(matchobj):\n",
    "        return ' ' + matchobj.group(0) + ' '\n",
    "    line = re.sub(ponctu,subfct1, line) # separate the punctuation from the words\n",
    "    \n",
    "    def subfct2(matchobj):\n",
    "        return matchobj.group(0)[:2]\n",
    "    line = re.sub(rep, subfct2,line) # keep maximum 2 consecutive identical character\n",
    "    \n",
    "    line = re.sub(hashtag,' hastag ', line) # replace every hastag with ' hastag '\n",
    "    line = re.sub(username,' username ', line) # replace every reference to a username with ' username '\n",
    "    line = re.sub(junk,' ', line) #throw away junk character\n",
    "    line = re.sub(number,' number ',line) # replace every number with ' number '\n",
    "    line = re.sub(emo, ' ',line) #suppr strange emoticon ( to modify ?)\n",
    "\n",
    "    line_split = [k for k,v in groupby(line.split())] #suprr repeated word:\n",
    "    line_split = line_split[:40] #trunc if too long\n",
    "    return line_split\n",
    "\n",
    "def custom_tokenizer_text(text): # create a tokenizer function\n",
    "    return clean_line(text)\n",
    "\n",
    "def custom_preprocess_label(label):\n",
    "    label = int(label)\n",
    "    if label == 4:\n",
    "        label = 1\n",
    "    return str(label)\n",
    "\n",
    "import pickle\n",
    "store_model_path = '/stockage/Research_Team_Ressources/Adrien/VAE_text/'\n",
    "try:\n",
    "    with open(store_model_path +'Field_def.pickle', 'rb') as my_pickle:\n",
    "        TEXT = pickle.load(my_pickle)\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "LABEL = data.Field(sequential=False, preprocessing=custom_preprocess_label, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/stockage/Research_Team_Ressources/Sentiment140/training.1600000.processed.noemoticon.utf8.csv'\n",
    "from torchtext import data\n",
    "from torch.utils.data import Dataset\n",
    "dataset = data.TabularDataset(\n",
    "        path= data_path, format='csv',\n",
    "        fields=[('Num', None),('Label', LABEL), ('id', None), ('date',None),\n",
    "                ('flag', None),('user', None),('Text', TEXT)],\n",
    "        skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7faeb3922470>,\n",
       " <torchtext.data.example.Example at 0x7faeb39224a8>,\n",
       " <torchtext.data.example.Example at 0x7faeb39224e0>,\n",
       " <torchtext.data.example.Example at 0x7faeb3922438>,\n",
       " <torchtext.data.example.Example at 0x7faeb39226a0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.examples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 1000000\n",
    "ratio_train = nb_train / len(dataset)\n",
    "nb_test = 500000\n",
    "ratio_test = nb_test / len(dataset)\n",
    "ratio_other = 1 - ratio_train - ratio_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, other_dataset, test_dataset = dataset.split(split_ratio=[ratio_train,ratio_test,ratio_other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "train_iter, test_iter = BucketIterator.splits(\n",
    " (train_dataset, test_dataset), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(batch_size, batch_size),\n",
    " device=num_device, # if you want to use the GPU, specify the GPU number here\n",
    " sort_key=lambda x: len(x.Text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        self.trg = trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_class(data_iter, nbatches = None):\n",
    "    iterator = iter(data_iter)\n",
    "    len_max = len(data_iter)\n",
    "    if nbatches == None:\n",
    "        nbatches = len_max\n",
    "    elif nbatches > len_max:\n",
    "        nbatches = len_max\n",
    "    for i in range(nbatches):\n",
    "        bb = next(iterator)\n",
    "        yield Batch(bb.Text[0].permute(1,0), bb.Label, TEXT.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully convolutional NN (with global pooling for managing different length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.embed = nn.Embedding(input_size, embed_size)        \n",
    "        self.conv1dBlock1 = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, 20, 3, padding=1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv1dBlock2 = nn.Sequential(\n",
    "            nn.Conv1d(20, 2, 3, padding=1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.conv1dBlock1(x)\n",
    "        x = self.conv1dBlock2(x)\n",
    "        out = torch.mean(x, dim=2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(TEXT.vocab)\n",
    "model = ConvNet(n_vocab, embed_size=300, num_classes = 2).to(device)\n",
    "# This was important from their code. \n",
    "# Initialize parameters with Glorot / fan_avg.\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "generator = data_gen_class(train_iter)\n",
    "bat = next(generator)\n",
    "outputs = model.forward(bat.src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, criterion, opt=None):\n",
    "    nb_batches = len(data_iter)\n",
    "    generator = data_gen_class(data_iter)\n",
    "    nb_item = 0\n",
    "    total_loss = 0\n",
    "    acc_y_sum = 0\n",
    "    \n",
    "    temp_nb_item = 0\n",
    "    temp_total_loss = 0\n",
    "    temp_acc_y_sum = 0\n",
    "    \n",
    "    for i, batch in enumerate(generator):\n",
    "        #Forward pass\n",
    "        outputs = model.forward(batch.src)\n",
    "        loss = criterion(outputs, batch.trg)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        temp_total_loss += loss.item()\n",
    "        acc_y = torch.argmax(outputs,dim=1) == batch.trg\n",
    "        acc_y = acc_y.float().sum().item()\n",
    "        acc_y_sum += acc_y\n",
    "        temp_acc_y_sum += acc_y\n",
    "        nb_item  += batch.src.size(0)\n",
    "        temp_nb_item += batch.src.size(0)\n",
    "        \n",
    "        if opt is not None:\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 1000 == 0:\n",
    "                print ('Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}' .format(i+1, nb_batches, temp_total_loss/temp_nb_item, temp_acc_y_sum/temp_nb_item))\n",
    "                temp_acc_y_sum = 0\n",
    "                temp_nb_item = 0\n",
    "                temp_total_loss = 0\n",
    "    \n",
    "    return total_loss/nb_item, acc_y_sum/nb_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type ConvNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0\n",
      "Step [1000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [2000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [3000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [4000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [5000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [6000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [7000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [8000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [9000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [10000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [11000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [12000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [13000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [14000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [15000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [16000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [17000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [18000/31250], Loss: 0.0142, Accuracy: 0.79\n",
      "Step [19000/31250], Loss: 0.0144, Accuracy: 0.80\n",
      "Step [20000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [21000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [22000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [23000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [24000/31250], Loss: 0.0144, Accuracy: 0.80\n",
      "Step [25000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [26000/31250], Loss: 0.0142, Accuracy: 0.79\n",
      "Step [27000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [28000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [29000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [30000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [31000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "1000000\n",
      "(0.014252174451485276, 0.796193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "(0.014526815623097121, 0.809314)\n",
      "CPU times: user 2min 46s, sys: 20.3 s, total: 3min 6s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epoch = 1\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"epoch : \", epoch)\n",
    "    model.train()\n",
    "    print(run_epoch(train_iter, model,criterion, optimizer))\n",
    "    model.eval()\n",
    "    print(run_epoch(test_iter, model,criterion, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.014526815623097121, 0.809314)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(run_epoch(test_iter, model, criterion, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(TEXT,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {key : value for key, value in TEXT.vocab.stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {value : key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def sentence_to_vec(sent_vect):\n",
    "    tokenizer = Tokenizer(oov_token=TEXT.unk_token)\n",
    "    tokenizer.fit_on_texts(\"\")\n",
    "    tokenizer.word_index = word_index\n",
    "    text_to_decode = [sent_vect]\n",
    "    sequences = [[word_index[\"§\"]] + tokenizer.texts_to_sequences(text_to_decode)[0]]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,  6724]], device='cuda:0')\n",
      "Prediction :  [[0.5565129  0.44348708]]\n"
     ]
    }
   ],
   "source": [
    "sent = torch.from_numpy(np.asarray(sentence_to_vec(\"python\"))).to(device)\n",
    "print(sent)\n",
    "model.eval()\n",
    "tmp = model.forward(sent)\n",
    "print(\"Prediction : \",F.softmax(tmp, dim = 1).to(torch.device(\"cpu\")).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
