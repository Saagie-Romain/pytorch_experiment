{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and gpu init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "num_device = 0\n",
    "device = torch.device(\"cuda:\" + str(num_device) if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(num_device)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessings and iterators on train/test dataset for batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from itertools import groupby\n",
    "def clean_line(line):\n",
    "    hashtag = re.compile('#[^ \\t\\n\\r\\f\\v]+')\n",
    "    username = re.compile('@[^ \\t\\n\\r\\f\\v]+')\n",
    "    url = re.compile('https?[^ \\t\\n\\r\\f\\v]*')\n",
    "    junk = re.compile('[\"¤#%&()*+-/;<=>@[\\]^_`{|}~\\\\;\\(\\)\\'\\\"\\*\\`\\´\\‘\\’…\\\\\\/\\{\\}\\|\\+><~\\[\\]\\“\\”%=\\$§]')\n",
    "    ponctu = re.compile('[.!?,:]')\n",
    "    number = re.compile('(^[0-9]+)|([0-9]+)')\n",
    "    rep = re.compile(r'(.)\\1{2,}')\n",
    "    emo = re.compile('[\\u233a-\\U0001f9ff]')\n",
    "\n",
    "    if line.startswith('\"') :\n",
    "        line = line[1:]\n",
    "    if line.endswith('\"') :\n",
    "        line = line[:-1]\n",
    "        \n",
    "    line = re.sub(url,' url ', line) # replace every url with ' url '\n",
    "    \n",
    "    def subfct1(matchobj):\n",
    "        return ' ' + matchobj.group(0) + ' '\n",
    "    line = re.sub(ponctu,subfct1, line) # separate the punctuation from the words\n",
    "    \n",
    "    def subfct2(matchobj):\n",
    "        return matchobj.group(0)[:2]\n",
    "    line = re.sub(rep, subfct2,line) # keep maximum 2 consecutive identical character\n",
    "    \n",
    "    line = re.sub(hashtag,' hastag ', line) # replace every hastag with ' hastag '\n",
    "    line = re.sub(username,' username ', line) # replace every reference to a username with ' username '\n",
    "    line = re.sub(junk,' ', line) #throw away junk character\n",
    "    line = re.sub(number,' number ',line) # replace every number with ' number '\n",
    "    line = re.sub(emo, ' ',line) #suppr strange emoticon ( to modify ?)\n",
    "\n",
    "    line_split = [k for k,v in groupby(line.split())] #suprr repeated word:\n",
    "    line_split = line_split[:40] #trunc if too long\n",
    "    return line_split\n",
    "\n",
    "def custom_tokenizer_text(text): # create a tokenizer function\n",
    "    return clean_line(text)\n",
    "\n",
    "def custom_preprocess_label(label):\n",
    "    label = int(label)\n",
    "    if label == 4:\n",
    "        label = 1\n",
    "    return str(label)\n",
    "\n",
    "import pickle\n",
    "store_model_path = '/stockage/Research_Team_Ressources/Adrien/VAE_text/'\n",
    "try:\n",
    "    with open(store_model_path +'Field_def.pickle', 'rb') as my_pickle:\n",
    "        TEXT = pickle.load(my_pickle)\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "LABEL = data.Field(sequential=False, preprocessing=custom_preprocess_label, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/stockage/Research_Team_Ressources/Sentiment140/training.1600000.processed.noemoticon.utf8.csv'\n",
    "from torchtext import data\n",
    "from torch.utils.data import Dataset\n",
    "dataset = data.TabularDataset(\n",
    "        path= data_path, format='csv',\n",
    "        fields=[('Num', None),('Label', LABEL), ('id', None), ('date',None),\n",
    "                ('flag', None),('user', None),('Text', TEXT)],\n",
    "        skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 1000000\n",
    "ratio_train = nb_train / len(dataset)\n",
    "nb_test = 500000\n",
    "ratio_test = nb_test / len(dataset)\n",
    "ratio_other = 1 - ratio_train - ratio_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, other_dataset, test_dataset = dataset.split(split_ratio=[ratio_train,ratio_test,ratio_other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "train_iter, test_iter = BucketIterator.splits(\n",
    " (train_dataset, test_dataset), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(batch_size, batch_size),\n",
    " device=num_device, # if you want to use the GPU, specify the GPU number here\n",
    " sort_key=lambda x: len(x.Text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        self.trg = trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_class(data_iter, nbatches = None):\n",
    "    iterator = iter(data_iter)\n",
    "    len_max = len(data_iter)\n",
    "    if nbatches == None:\n",
    "        nbatches = len_max\n",
    "    elif nbatches > len_max:\n",
    "        nbatches = len_max\n",
    "    for i in range(nbatches):\n",
    "        bb = next(iterator)\n",
    "        yield Batch(bb.Text[0].permute(1,0), bb.Label, TEXT.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully convolutional NN (with global pooling for managing different length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "        self.embed = nn.Embedding(input_size, embed_size)        \n",
    "    \n",
    "        self.conv1dBlock1 = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, 20, 3, padding=1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv1dBlock2 = nn.Sequential(\n",
    "            nn.Conv1d(20, 2, 3, padding=1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "#         self.fc = nn.Linear(5, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(x.size())\n",
    "        x = self.embed(x)\n",
    "#         print(x.size())\n",
    "        x = x.transpose(1,2)\n",
    "#         print(x.size())\n",
    "               \n",
    "        x = self.conv1dBlock1(x)\n",
    "#         print(x.size())\n",
    "        x = self.conv1dBlock2(x)\n",
    "#         print(x.size())\n",
    "        #Global Mean Pooling\n",
    "        out = torch.mean(x, dim=2)\n",
    "#         print(x.size())\n",
    "\n",
    "#         out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(TEXT.vocab)\n",
    "model = ConvNet(n_vocab, embed_size=300, num_classes = 2).to(device)\n",
    "# This was important from their code. \n",
    "# Initialize parameters with Glorot / fan_avg.\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "generator = data_gen_class(train_iter)\n",
    "bat = next(generator)\n",
    "outputs = model.forward(bat.src)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.Conv1d(200, 10, 2) # in-channels = 200, out-channels = 10\n",
    "# input = Variable(torch.randn(10, 200, 5)) # 200 = embedding dim, 5 = seq length\n",
    "# feature_maps = m(input)\n",
    "# print(feature_maps.size()) # feature_maps size = 10,10,4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, criterion, opt=None):\n",
    "    nb_batches = len(data_iter)\n",
    "    generator = data_gen_class(data_iter)\n",
    "    nb_item = 0\n",
    "    total_loss = 0\n",
    "    acc_y_sum = 0\n",
    "    \n",
    "    temp_nb_item = 0\n",
    "    temp_total_loss = 0\n",
    "    temp_acc_y_sum = 0\n",
    "    \n",
    "    for i, batch in enumerate(generator):\n",
    "        #Forward pass\n",
    "        outputs = model.forward(batch.src)\n",
    "        loss = criterion(outputs, batch.trg)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        temp_total_loss += loss.item()\n",
    "        acc_y = torch.argmax(outputs,dim=1) == batch.trg\n",
    "        acc_y = acc_y.float().sum().item()\n",
    "        acc_y_sum += acc_y\n",
    "        temp_acc_y_sum += acc_y\n",
    "        nb_item  += batch.src.size(0)\n",
    "        temp_nb_item += batch.src.size(0)\n",
    "        \n",
    "        if opt is not None:\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 1000 == 0:\n",
    "                print ('Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}' \n",
    "                       .format(i+1, nb_batches, temp_total_loss/temp_nb_item, temp_acc_y_sum/temp_nb_item))\n",
    "                temp_acc_y_sum = 0\n",
    "                temp_nb_item = 0\n",
    "                temp_total_loss = 0\n",
    "    \n",
    "    print(nb_item)\n",
    "    return total_loss/nb_item, acc_y_sum/nb_item\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0\n",
      "Step [1000/31250], Loss: 0.0198, Accuracy: 0.68\n",
      "Step [2000/31250], Loss: 0.0178, Accuracy: 0.75\n",
      "Step [3000/31250], Loss: 0.0169, Accuracy: 0.76\n",
      "Step [4000/31250], Loss: 0.0164, Accuracy: 0.76\n",
      "Step [5000/31250], Loss: 0.0161, Accuracy: 0.76\n",
      "Step [6000/31250], Loss: 0.0158, Accuracy: 0.77\n",
      "Step [7000/31250], Loss: 0.0156, Accuracy: 0.77\n",
      "Step [8000/31250], Loss: 0.0156, Accuracy: 0.77\n",
      "Step [9000/31250], Loss: 0.0154, Accuracy: 0.78\n",
      "Step [10000/31250], Loss: 0.0154, Accuracy: 0.78\n",
      "Step [11000/31250], Loss: 0.0154, Accuracy: 0.77\n",
      "Step [12000/31250], Loss: 0.0152, Accuracy: 0.78\n",
      "Step [13000/31250], Loss: 0.0152, Accuracy: 0.78\n",
      "Step [14000/31250], Loss: 0.0152, Accuracy: 0.78\n",
      "Step [15000/31250], Loss: 0.0151, Accuracy: 0.78\n",
      "Step [16000/31250], Loss: 0.0151, Accuracy: 0.78\n",
      "Step [17000/31250], Loss: 0.0151, Accuracy: 0.78\n",
      "Step [18000/31250], Loss: 0.0151, Accuracy: 0.78\n",
      "Step [19000/31250], Loss: 0.0150, Accuracy: 0.78\n",
      "Step [20000/31250], Loss: 0.0149, Accuracy: 0.78\n",
      "Step [21000/31250], Loss: 0.0151, Accuracy: 0.78\n",
      "Step [22000/31250], Loss: 0.0150, Accuracy: 0.78\n",
      "Step [23000/31250], Loss: 0.0150, Accuracy: 0.78\n",
      "Step [24000/31250], Loss: 0.0149, Accuracy: 0.78\n",
      "Step [25000/31250], Loss: 0.0147, Accuracy: 0.79\n",
      "Step [26000/31250], Loss: 0.0149, Accuracy: 0.78\n",
      "Step [27000/31250], Loss: 0.0147, Accuracy: 0.79\n",
      "Step [28000/31250], Loss: 0.0148, Accuracy: 0.79\n",
      "Step [29000/31250], Loss: 0.0147, Accuracy: 0.79\n",
      "Step [30000/31250], Loss: 0.0148, Accuracy: 0.79\n",
      "Step [31000/31250], Loss: 0.0147, Accuracy: 0.79\n",
      "1000000\n",
      "(0.015452581693142653, 0.774639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "(0.01569111578733474, 0.808364)\n",
      "epoch :  1\n",
      "Step [1000/31250], Loss: 0.0144, Accuracy: 0.80\n",
      "Step [2000/31250], Loss: 0.0145, Accuracy: 0.79\n",
      "Step [3000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [4000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [5000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [6000/31250], Loss: 0.0145, Accuracy: 0.79\n",
      "Step [7000/31250], Loss: 0.0143, Accuracy: 0.80\n",
      "Step [8000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [9000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [10000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [11000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [12000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [13000/31250], Loss: 0.0145, Accuracy: 0.79\n",
      "Step [14000/31250], Loss: 0.0145, Accuracy: 0.79\n",
      "Step [15000/31250], Loss: 0.0144, Accuracy: 0.80\n",
      "Step [16000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [17000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [18000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [19000/31250], Loss: 0.0145, Accuracy: 0.79\n",
      "Step [20000/31250], Loss: 0.0145, Accuracy: 0.79\n",
      "Step [21000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [22000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [23000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [24000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [25000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [26000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [27000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [28000/31250], Loss: 0.0144, Accuracy: 0.80\n",
      "Step [29000/31250], Loss: 0.0144, Accuracy: 0.79\n",
      "Step [30000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [31000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "1000000\n",
      "(0.014382807996451854, 0.794128)\n",
      "500000\n",
      "(0.01550111321489513, 0.812724)\n",
      "epoch :  2\n",
      "Step [1000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [2000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [3000/31250], Loss: 0.0139, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [5000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [6000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [7000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [8000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [9000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [10000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [11000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [12000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [13000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [14000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [15000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [16000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [17000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [18000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [19000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [20000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [21000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [22000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [23000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [24000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [25000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [26000/31250], Loss: 0.0142, Accuracy: 0.80\n",
      "Step [27000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [28000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "Step [29000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [30000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [31000/31250], Loss: 0.0143, Accuracy: 0.79\n",
      "1000000\n",
      "(0.014076402415275574, 0.799378)\n",
      "500000\n",
      "(0.01575565145845711, 0.813126)\n",
      "epoch :  3\n",
      "Step [1000/31250], Loss: 0.0137, Accuracy: 0.80\n",
      "Step [2000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [3000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [5000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [6000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [7000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [8000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [9000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [10000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [11000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [12000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [14000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [15000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "Step [16000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [17000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [18000/31250], Loss: 0.0139, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [20000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [21000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [22000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [23000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [25000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [26000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [27000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [28000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [29000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [30000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0141, Accuracy: 0.80\n",
      "1000000\n",
      "(0.013872983420178293, 0.80328)\n",
      "500000\n",
      "(0.01501746322657913, 0.814364)\n",
      "epoch :  4\n",
      "Step [1000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [2000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [3000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [5000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [6000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [8000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [9000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [10000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [11000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [12000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [14000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [15000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [16000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "Step [17000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [18000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [20000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [21000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [22000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [23000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [25000/31250], Loss: 0.0140, Accuracy: 0.80\n",
      "Step [26000/31250], Loss: 0.0137, Accuracy: 0.80\n",
      "Step [27000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [28000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [29000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [30000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [31000/31250], Loss: 0.0139, Accuracy: 0.80\n",
      "1000000\n",
      "(0.013708039789915085, 0.806183)\n",
      "500000\n",
      "(0.015399843849204481, 0.813178)\n",
      "epoch :  5\n",
      "Step [1000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [2000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [3000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [5000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [6000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [8000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [9000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [10000/31250], Loss: 0.0138, Accuracy: 0.80\n",
      "Step [11000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [12000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [14000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [15000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [16000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [17000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [18000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [20000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [21000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [22000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [23000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [25000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [27000/31250], Loss: 0.0137, Accuracy: 0.80\n",
      "Step [28000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [29000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [30000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "1000000\n",
      "(0.013598634614214301, 0.80827)\n",
      "500000\n",
      "(0.015627296622507274, 0.814526)\n",
      "epoch :  6\n",
      "Step [1000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [2000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [3000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [5000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [6000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [8000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [9000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [10000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [11000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [12000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [14000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [15000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [16000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [17000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [18000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [21000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [22000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [23000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0137, Accuracy: 0.80\n",
      "Step [25000/31250], Loss: 0.0138, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [27000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [28000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [29000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [30000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "1000000\n",
      "(0.013486119922265411, 0.810645)\n",
      "500000\n",
      "(0.015722132459513843, 0.814322)\n",
      "epoch :  7\n",
      "Step [1000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [5000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [6000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [8000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [9000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [10000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [11000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [14000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [15000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [16000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [17000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [18000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [20000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [21000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [22000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [23000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [25000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [27000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [28000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [29000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [30000/31250], Loss: 0.0135, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "1000000\n",
      "(0.01340168845064938, 0.811682)\n",
      "500000\n",
      "(0.01538141530789435, 0.81579)\n",
      "epoch :  8\n",
      "Step [1000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [2000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [3000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [6000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [8000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [12000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [14000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [16000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [17000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [18000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [20000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [21000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0136, Accuracy: 0.81\n",
      "Step [23000/31250], Loss: 0.0134, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [25000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [27000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [28000/31250], Loss: 0.0137, Accuracy: 0.81\n",
      "Step [29000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [30000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "1000000\n",
      "(0.013300137044668198, 0.813434)\n",
      "500000\n",
      "(0.015360894553214311, 0.814812)\n",
      "epoch :  9\n",
      "Step [1000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [2000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [16000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [17000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [18000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [21000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [22000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [23000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "1000000\n",
      "(0.01320609664325416, 0.815145)\n",
      "500000\n",
      "(0.015422903067030013, 0.814632)\n",
      "epoch :  10\n",
      "Step [1000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [9000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [10000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [21000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [22000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "Step [23000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [24000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [25000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [28000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [29000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0134, Accuracy: 0.81\n",
      "1000000\n",
      "(0.01314749400177598, 0.81599)\n",
      "500000\n",
      "(0.015024166279129683, 0.81452)\n",
      "epoch :  11\n",
      "Step [1000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [4000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [7000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [9000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [11000/31250], Loss: 0.0133, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [13000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [17000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [19000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [27000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "1000000\n",
      "(0.013087827438697219, 0.817259)\n",
      "500000\n",
      "(0.015449154272980988, 0.815482)\n",
      "epoch :  12\n",
      "Step [1000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0130, Accuracy: 0.81\n",
      "Step [14000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0133, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0132, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [30000/31250], Loss: 0.0132, Accuracy: 0.81\n",
      "Step [31000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "1000000\n",
      "(0.013034525863975287, 0.817866)\n",
      "500000\n",
      "(0.0155596089367792, 0.813232)\n",
      "epoch :  13\n",
      "Step [1000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [26000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012958758265025913, 0.819086)\n",
      "500000\n",
      "(0.015756803346708415, 0.814668)\n",
      "epoch :  14\n",
      "Step [1000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012930061183646322, 0.81965)\n",
      "500000\n",
      "(0.015912532269723712, 0.815096)\n",
      "epoch :  15\n",
      "Step [1000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [3000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [4000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0127, Accuracy: 0.83\n",
      "Step [13000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0131, Accuracy: 0.81\n",
      "Step [27000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012877331978142262, 0.820909)\n",
      "500000\n",
      "(0.015405743680395186, 0.81463)\n",
      "epoch :  16\n",
      "Step [1000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [7000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012810495219022035, 0.821914)\n",
      "500000\n",
      "(0.01598988298780471, 0.814414)\n",
      "epoch :  17\n",
      "Step [1000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0127, Accuracy: 0.83\n",
      "Step [3000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [4000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0128, Accuracy: 0.83\n",
      "Step [7000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [9000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0127, Accuracy: 0.83\n",
      "Step [14000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [16000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0131, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012792847728848457, 0.822173)\n",
      "500000\n",
      "(0.0159383511178419, 0.81507)\n",
      "epoch :  18\n",
      "Step [1000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [2000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [3000/31250], Loss: 0.0125, Accuracy: 0.83\n",
      "Step [4000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [5000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [9000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [10000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [13000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [14000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [20000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [28000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012733946047648787, 0.823186)\n",
      "500000\n",
      "(0.016245843117676677, 0.813624)\n",
      "epoch :  19\n",
      "Step [1000/31250], Loss: 0.0124, Accuracy: 0.83\n",
      "Step [2000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [3000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0124, Accuracy: 0.83\n",
      "Step [5000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [6000/31250], Loss: 0.0124, Accuracy: 0.83\n",
      "Step [7000/31250], Loss: 0.0125, Accuracy: 0.83\n",
      "Step [8000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [9000/31250], Loss: 0.0127, Accuracy: 0.83\n",
      "Step [10000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [11000/31250], Loss: 0.0127, Accuracy: 0.83\n",
      "Step [12000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [13000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [15000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [17000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [18000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [19000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [20000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [21000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [22000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [23000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [24000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [25000/31250], Loss: 0.0128, Accuracy: 0.82\n",
      "Step [26000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [27000/31250], Loss: 0.0127, Accuracy: 0.83\n",
      "Step [28000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [29000/31250], Loss: 0.0130, Accuracy: 0.82\n",
      "Step [30000/31250], Loss: 0.0129, Accuracy: 0.82\n",
      "Step [31000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "1000000\n",
      "(0.012704977662689984, 0.823611)\n",
      "500000\n",
      "(0.016407788374558092, 0.81339)\n",
      "epoch :  20\n",
      "Step [1000/31250], Loss: 0.0125, Accuracy: 0.83\n",
      "Step [2000/31250], Loss: 0.0125, Accuracy: 0.83\n",
      "Step [3000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [4000/31250], Loss: 0.0124, Accuracy: 0.83\n",
      "Step [5000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [6000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [7000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [8000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [9000/31250], Loss: 0.0125, Accuracy: 0.83\n",
      "Step [10000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [11000/31250], Loss: 0.0126, Accuracy: 0.82\n",
      "Step [12000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [13000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [14000/31250], Loss: 0.0126, Accuracy: 0.83\n",
      "Step [15000/31250], Loss: 0.0127, Accuracy: 0.82\n",
      "Step [16000/31250], Loss: 0.0128, Accuracy: 0.82\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-447-b5cf862451d2>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, criterion, opt)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtemp_acc_y_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2e173bda7b91>\u001b[0m in \u001b[0;36mdata_gen_class\u001b[0;34m(data_iter, nbatches)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 yield Batch(minibatch, self.dataset, self.device,\n\u001b[0;32m--> 151\u001b[0;31m                             self.train)\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device, train)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device, train)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[1;32m    187\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device, train)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"epoch : \", epoch)\n",
    "    model.train()\n",
    "    print(run_epoch(train_iter, model,criterion, optimizer))\n",
    "    model.eval()\n",
    "    print(run_epoch(test_iter, model,criterion, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/stockage/programs/pyenv/versions/3.5.5/lib/python3.5/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "(0.014900214263267816, 0.795854)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(run_epoch(test_iter, model,criterion, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {key : value for key, value in TEXT.vocab.stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {value : key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def sentence_to_vec(sent_vect):\n",
    "    tokenizer = Tokenizer(oov_token=TEXT.unk_token)\n",
    "    tokenizer.fit_on_texts(\"\")\n",
    "    tokenizer.word_index = word_index\n",
    "    text_to_decode = [sent_vect]\n",
    "    sequences = [[word_index[\"§\"]] + tokenizer.texts_to_sequences(text_to_decode)[0]]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,  6724]], device='cuda:0')\n",
      "Prediction :  [[0.5565129  0.44348708]]\n"
     ]
    }
   ],
   "source": [
    "sent = torch.from_numpy(np.asarray(sentence_to_vec(\"python\"))).to(device)\n",
    "print(sent)\n",
    "model.eval()\n",
    "tmp = model.forward(sent)\n",
    "print(\"Prediction : \",F.softmax(tmp, dim = 1).to(torch.device(\"cpu\")).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
